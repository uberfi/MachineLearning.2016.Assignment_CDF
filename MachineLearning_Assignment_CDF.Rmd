---
title: "MachineLearning_Assignment"
author: "CDF"
date: "February 13, 2016"
output: html_document
---

### Background

The data being analyzed for this assignment comes from a study on ‘quality of execution’ that “investigate[d] three aspects that pertain to qualitative activity recognition: specifying correct execution, detecting execution mistakes, providing [real-time] feedback to the user.” (Velloso, Bulling, Gellersen, et al., 2013, n.p.). The study involved six 20-28 years old male participants “asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes” (ibid., n.p.). A report of the study can be downloaded from <http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf>. 

### Method

#### Data
The training data for this project are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>. The test data are available here:<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>. The aforementioned data were sourced from <http://groupware.les.inf.puc-rio.br/har>. The raw data were generated by sensors on the body (belt, glove, arm) and on the dumbbell. As per the description of the data, the Class (A, B, C, D or E) represents the response variable, and the other features form the the set of possible predictors.

#### Analytical Procedure
Once the data was downloaded locally, the comma separated value (CSV) Excel files were reviewed manually to get a sense of the data. The datasets also include computed derived (computed) values such as kurtosis, variance, range, …The prevalence of NA and missing values for certain features was instructive for data preprocessing ahead of model building.  Once the data was loaded, the datasets were preprocessed to remove all NA and missing values. 

###### Load the data and "clean" the data

```{r}
setwd("~/Desktop/DataScience_MOOC/MachineLearning")
trainData <- read.csv("assignTrainData.csv", header = TRUE)
testData <- read.csv("assignTestData.csv",  header = TRUE)
str(trainData, list.len = 5) # truncated for publication purposes
# names(trainData) # surpressed for publication purposes

# subset the data by removing the initial identifiers
# convert variables into numerics 
# (do not turn the response variable to numeric)

trainData2 <- trainData[, -c(1:7,160)] 
trainData2 <- lapply(trainData2, as.numeric)
trainData3 <- as.data.frame(trainData2)
# names(trainData3) # surpressed for publication purposes

# caret
library(caret)

# remove zero to near-zero variance features
nzvTrain <- nearZeroVar(trainData3)
train <- trainData3[, -nzvTrain]

str(train, list.len = 10)
# summary(train) # surpressed for publication purposes

# there seems to be 19216 NA values in some of the features.
# in order to address the NA's, imputation of the median scores was deployed
# allowed for the preservation of the features

cleanup <- function(x) {
  ## ASSUME all columns should be numeric
  if (is.factor(x) || is.character(x)) {
    x <- suppressWarnings(as.numeric(as.character(x)))
  }

  ## impute median
  
  m <- median(x,na.rm=TRUE)
  x[is.na(x)] <- m
  return(x)
}
  
# cleanup the columns of the data frame train
# by imputing the median score of the 406 cases with non-NA/missing values
# for each of the affected feature

train[] <- lapply(train,cleanup)

# summary(train) # surpressed for publication purposes
mean(is.na(train))

# summary(train) # surpressed for publication purposes
str(train, list.len = 5)


# investigate and remove highly correlated features
trainCor <- train[,-c(94)] # do not consider the response variable
# summary(trainCor) # surpressed for publication purposes

descrCor <- cor(trainCor)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
highCorr # Non perfectly correlated features

# dealing with high correlations 
# to remove features with absolute correlatiopns above 0.75
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
trainCor <- trainCor[,-highlyCorDescr]
descrCor2 <- cor(trainCor)
summary(descrCor2[upper.tri(descrCor2)]) # the range of correlations retained

str(trainCor, list.len = 5) # truncated for publication purposes

# pull the predictors from the train set to subset the test set; then ready the test set for prediction
predictors <- names(trainCor)

# create a preliminary trainSet
# may have to further subset the trainSet should there be need based on the sparsity of the testSet
trainSet <- trainCor
str(trainSet, list.len = 5) # truncated for publication purposes
# summary(trainSet) # surpressed for publication purposes, but please reproduce to get a better picture

# ready the test data
# subset the testData for just the variables in the trainSet
# bring the two sets into alignment before prediction
testData2 <- testData[, predictors]
str(testData2, list.len = 10) # truncated for publication purposes
# summary(testData2) # surpressed for publication purposes
testData2 <- lapply(testData2, as.numeric)
testData2 <- as.data.frame(testData2)
# summary(testData2) # surpressed for publication purposes

# the test data contains features that has NA or missing values for all 20 cases
# remove these features with zero to near-zero variances
# the practical effect is to remove all the features which had all NA or missing values
nzvTest <- nearZeroVar(testData2)
test <- testData2[, -nzvTest]
# summary(test) # surpressed for publication purposes, please run to reproduce the result

testSet <- test
str(testSet, list.len = 5)
# summary(testSet) # surpressed for publication purposes, please run to reproduce the result

# use the predictors in the testSet to futher distill the feature space of the trainSet
predictors2 <- names(testSet)
trainSet <- trainSet[, predictors2]
trainSet$classe <- as.factor(trainData$classe)

str(trainSet, list.len = 5) # truncated for publication purposes
# summary(trainSet) # surpressed for publication purposes 

# Check for missing or NA
mean(is.na(trainSet))
mean(is.na(testSet))
```

#### Modeling

Chose to deploy the random forest algorithm because of its robustness
for classification.


```{r}

# repetition of the cross validation method = "repeatedcv" is computationally intensive 
# and hence it was abandoned after hours of running, lest the perfect become the enemy of the good
# moreover, the 10-fold, without repetition took hours to run and had to be halted.
# hence, the model, although not perfect tried 5-fold CV; that also was computationally intensive
# finally resorted to 3-fold CV

set.seed(121)

modFit <- train(classe ~., method = "rf", data=trainSet, 
                trControl = trainControl(method = "cv", number = 3),
                prox = TRUE)

modFit

# check the in-sample accuracy of the model ModFit
confusionMatrix((predict(modFit, trainSet)), trainSet$classe)

```

Check for the importance of the variables

```{r}
varImp(modFit, useModel=TRUE, scale=FALSE)
varImp(modFit, useModel=TRUE, scale=TRUE)
```

Predict outcomes for test data set using the random forest model

```{r}
pred <- predict(modFit, newdata=testSet)
pred

```

"The 10-fold CV error rate [can] provide[s] a pretty good approximation to the test error rate." (James, Witten, Hastie, & Tibshirani, 2013, p. 186).

Hence, the aforementioned accuracy provides some idea of the errors we should expect from deploying
the model to classify the testSet of 20 cases.

### Concluding Remarks

The results are contingent on the data preprocessing processes, including
the imputation of the median values for each of the features that had 19216 NA or missing values.
Another possible approaches would have been to delete those features since majority of the
values were missing, or to remove all cases with NA or missing values, which would have drastically
reduce the cases (to N = 406) and hence reduced the power of the model to properly predict out-of-sample cases


### References

1. Velloso, E., Bulling, A., Gellersen, H., Ugulino, W., and Fuks, H. (2013). Qualitative activity recognition of weight lifting exercises. Proceedings of the 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13). Stuggart, Germany: ACM SIGCHI, 2013. <http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf>.


2. <http://stackoverflow.com/questions/31813675/brief-standard-code-to-clean-most-common-data-frame-invalid-entries>

3. James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013). An introduction to statistical learning: with application in R. New York, NY: Springer Science+Business Media.